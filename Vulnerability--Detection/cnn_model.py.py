# coding:utf-8

from keras.models import Model
from keras.layers import Dense, Dropout, Input, Embedding
from keras.layers.convolutional import Convolution1D

from keras.layers.pooling import MaxPooling1D, GlobalMaxPooling1D
from keras.layers import Flatten

from keras.optimizers import RMSprop
from keras.callbacks import Callback

from sklearn.metrics import f1_score, precision_score, recall_score
import keras.backend as K



def get_f1( y_pred, y_true ):
    # fileW = open(log_name, 'a+')
    
    val_predict = copy.deepcopy( y_pred )
    true = copy.deepcopy( y_true )
    tmp_v_f1 = []
    tmp_v_pre = []
    tmp_v_rec = []
    kk = np.unique(val_predict)
    for val in kk:
        val_p = copy.deepcopy(val_predict)
        val_p[val_p >= val] =1
        val_p[val_p < val] =0

        _val_f1 = f1_score(true, val_p)
        _val_recall = recall_score(true, val_p)
        _val_precision = precision_score(true, val_p)

        tmp_v_f1.append( _val_f1 )
        tmp_v_rec.append( _val_precision )
        tmp_v_pre.append( _val_recall )

    index_1 = np.argmax(tmp_v_f1)
    print( kk[index_1] )
    f1 = tmp_v_f1[index_1]
    r = tmp_v_rec[index_1]
    p = tmp_v_pre[index_1]
    # fileW.write(time.strftime("%m-%d %H:%M:%S--", time.localtime()) + "f1:%.4f R:%.4f P:%.4f\n"%( f1, r, p))
    print( time.strftime("%m-%d %H:%M:%S--", time.localtime()) + "f1:%.4f R:%.4f P:%.4f\n"%( f1, r, p) )
    # fileW.close()
    return f1

class two_input_Metrics(Callback):
    def on_train_begin(self, logs={}):
        self.val_f1s = []
        self.val_recalls = []
        self.val_precisions = []
    def on_epoch_end(self, epoch, logs={}):
        pre = np.asarray(self.model.predict(self.validation_data[0:2]))#.round()
        true = self.validation_data[2]
#         fileW = open(log_name, 'a+')
#         fileW.write( "########### epoch: "+str( epoch + 1 )+"  ###########\n" )
#         fileW.close()
        get_f1(pre, true)
        return

class three_input_Metrics(Callback):
    def on_train_begin(self, logs={}):
        self.val_f1s = []
        self.val_recalls = []
        self.val_precisions = []
    def on_epoch_end(self, epoch, logs={}):
        pre = np.asarray(self.model.predict(self.validation_data[0:3]))#.round()
        true = self.validation_data[3]
#         fileW = open(log_name, 'a+')
#         fileW.write( "########### epoch: "+str( epoch + 1 )+"  ###########\n" )
#         fileW.close()
        get_f1(pre, true)
        return


def CNN(text_mxlen):
    text_inputs = Input(shape=[text_mxlen])
    embedded_sequences = Embedding(max_words, 50, input_length=text_mxlen)(text_inputs)
    x = Convolution1D(128, kernel_size=5, padding='same')(embedded_sequences)
    x = Activation('relu')(x)    
    x = MaxPooling1D()(x)
    x = Dense(128)(x) #128
    # print(x.get_shape)
    x = MaxPooling1D()(x)
    res = Activation('relu')(x)
    res = Flatten()(res)
    # print( res.get_shape )
    res = Dense(64, activation='relu', name='FC3')(res)
    res = Dropout(0.5)(res)
    output = Dense(11, activation='sigmoid', name='out_layer')(res)
    model = Model(inputs=text_inputs, outputs=output)
    print( model.summary() )
    return model

metrics = one_input_Metrics()
model_1 = CNN(text_mxlen)

model_1.compile(loss='binary_crossentropy', optimizer='adamax')


model_1.fit(X_train[0],  y_train,  
            batch_size = 128, 
            epochs = 20,
            validation_data=[X_valida[0], y_valida], 
            callbacks=[metrics]
           )
model_name = str("../save_model/CNN--set_epoch-20.h5" )
model_1.save(model_name)



